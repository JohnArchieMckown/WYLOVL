TSP 4.2A on OS/MVS  rev. 6/25/91

This release is missing the Databank commands, pending some work
on converting old TSP databanks to the new format in TSP 4.2 which
is Fortran direct access, has fewer length restrictions, and allows
documentation stored with variables.  If you need to access old
databanks, use the previous version of TSP for now.  Eventually
we will have a free update with databank conversion and the new
databanks.  Send email to  TSPINTL@SUWATSON.BITNET  if you have
questions about this.

The FILE='filename string'  in READ and WRITE refers to a DDNAME.
If the string contains a period (.), the period and further
characters are ignored.  For example, FILE='FOO.DAT'  refers to
the DDNAME  FOO  (not to the DDNAME FOO.DAT).  The DDNAME  FOO
may then refer to the DSN FOO.DAT, of course.  This "feature"
is designed to make TSP programs easier to move from MVS to other
machines such as the PC, VM/CMS, VAX/VMS, unix, etc.

Sizes of TSP  (2M, 4M, 8M, 15M)
OS/MVS TSP 4.2 has the same array sizes in the different
load modules as VM/CMS.  To access them, use  PROG=TSP,
TSP4M, TSP8M or TSP15M (not BIGTSP, MAXITSP, etc. as in
previous OS/MVS releases).  They have not been tightly
sized to 2M, etc., so it may be possible to increase the
size of some of the internal arrays (SUBROUTINE FRESH,
source files E2, E4, E8, or E15) without running over the
indicated REGION.  Use the  SHOW;  TSP command when using
a given load module to display the dimensions.  The main
dimensions are:
      working space    # observations
2M       50000          2000
4M      450000         20000
8M     1500000         80000
15M    3500000         80000


                          New Features in TSP 4.2


New Time Series Estimation Techniques

     -  ARCH estimates the GARCH-M class of models, which allows the variance
     of the disturbance in a regression equation to evolve as an ARMA process
     whose mean is a function of a set of variables.  Special cases of this
     model are ordinary ARCH and weighted least squares.

     -  GMM (Generalized Method of Moments) uses instrumental variables or
     minimum distance estimators popularized by Hansen, Singleton, and others
     whereby the weighting matrix is (optionally) a heteroskedastic- and
     autocorrelation-consistent estimate.  GMM can be used to estimate
     parameters of a set of orthogonality conditions implied by a rational
     expectations model.  GMM is more general than that, however, and has
     applications outside of time series data.  GMM can handle several
     nonlinear equations with cross-equation restrictions, and the
     instrumental variables can vary by equation.

     -  KALMAN estimates linear regressions using the Kalman filter, as well as
     more elaborate state space models (time-varying parameters, adaptive
     regression, stochastically convergent parameters).  Multi-equation.

     -  VAR estimates vector autogressions (including exogenous variables) and
     calculates impulse response functions and variance decompositions.
     It can do responses for all permutations of Choleski factorings.


Other New Commands

     - CDF calculates tail probabilities (p-values) or critical values for the
     F, t, chi-squared, normal, and bivariate normal.  CDF can also calculate
     the significance levels for unit root testing (using the Dickey-Fuller
     methodology) and cointegration tests (using the Engle-Granger methodology)

     -  DOC creates and stores documentation for series or other variables in a
     TSP databank.

     -  HELP gives basic command syntax and is now available on all computers.

     -  MAT calculates a matrix algebra equation, using natural notation such
     as B = (X'X)"X'Y.  Operators available include addition, subtraction,
     multiplication, inversion, transpose, Kronecker product, and Hadamard
     product.  MAT provides many new matrix functions, such as CHOL, IDENT,
     EIGVAL, EIGVEC, VEC, VECH, DIAG, TR, DET, LOGDET, MIN, MAX, SUM,
     NROW, NCOL, and RANK.

      -  PANEL estimates linear regression models for balanced or unbalanced
      time series-cross section data.  PANEL can handle pooled, between, within
      (fixed effects), and variance components (random effects) models.
      Grouped means and tests for equality are also provided.  Fixed and
      random effects are done at the individual level only, but you can
      supply your own time dummies.


      -  REGOPT controls the calculation and display of regression diagnostics.
      Since a large number of new diagnostics have been added, REGOPT enables
      the user to customize his program to eliminate irrelevant diagnostics.
      P-values and stars can also be automatically computed for most statistics
      The new diagnostics are:
            DH (Durbin's h; alternative statistic DHALT also still available)
            LMARx (Breusch-Godfrey LM tests for autocorrelation of order x)
            QSTATx (Ljung-Box Q statistics for autocorrelation of order x)
            WNLAR (Wald test for AR(1) vs. misspecified dynamics)
            ADF (augmented Dickey-Fuller test for unit root of residual)
            ARCH (test for ARCH(1) residuals)
            RECRES (recursive residuals; useful for CUSUM, CUSUMSQ tests)
            CHOW (F-test for stability of coefficients in split sample)
            LRHET (LR test for heteroscedasticity in same split sample)
            WHITEHET (White het. test on cross-products of RHS variables)
            BPHET (Breusch-Pagan het. test on user-supplied list of variables)
            JB (Jarque-Bera test for normality of residuals)
            AIC (Akaike Information Criterion)
            SBIC (Schwarz Bayesian Information Criterion)

      -  SORT sorts one or more series, using one series as the key, and is
      useful for reordering panel data among other things.


New Features in Old Commands

ANALYZ - Names of calculated coefficients, their estimated values, standard
errors, and variance-covariance are now stored under the names @RNMSA, @COEFA,
@SESA, and @VCOVA so that several ANALYZs may be performed following a single
estimation (without destroying the input data required by ANALYZ).

BJEST - prints non-stationary roots even when the PRINT option is off.

CAPITL - END option causes end-of-period capital stock to be computed rather
than beginning-of-period.

CONVERT - can go to higher frequencies with duplication or interpolation.

FORM - Linear equations (FRMLs) for use in LSQ and other procedures can now be
formed automatically after OLSQ, INST, or AR1.  The NAR option allows easy
estimation of AR(p) models with LSQ.

LOGIT - The @DPDX and @DPDZ matrices are now printed by default and labelled
with the variable names and corresponding values of the dependent variable.

LSQ - handles unnormalized equations (first order/Euler conditions).

MFORM has the addition of a BLOCK option for forming block diagonal matrices.

MSD's ALL option computes skewness and kurtosis in addition to other statistics

Output with PDL variables has been rewritten to report unscrambled coefficients
only.  Thus, there is no longer any difficulty in using PDL equations for
forecasting, since coefficients of unscrambled variables are stored in the
equation.  A new option for Shiller distributed lags has been added to PDL
variables.  Shiller lags relax the polynomial constraint slightly.

OPTIONS - Addition of MEMORY= (for VAX and UNIX versions), LIMWARN= (suppresses
printing of warning messages), DOUBLE (specifies that all variables should
be stored in double precision), DISPLAY= (for PC Graphics version), and
SECONDS= (tells how often to update screen message in long procedures).

PRIN - Addition of MAXIT option to limit or extend the number of iterations
used to find the principal components.

READ/WRITE - Addition of BYSER option for reading data matrix in transposed
form (by series instead of observation), FORMAT=RB8 for double precision binary
format, and FORMAT=LOTUS for PC version to read Lotus or other spreadsheet
files (already released in PC TSP 4.1C version).


General Improvements

All scalars (CONSTs or PARAMs) are now stored as double precision for improved
accuracy.

Previous limits on matrix size (<16384 elements) or time series length (<32768)
have been removed, as have the limits on the number of instruments or
endogenous variables.  There is still a fixed limit on time series length
in any version (usually about 25,000), but it can be increased to any
number if you have the source code (mainframe) or ask for a custom 386
version.  The  SHOW;  command now displays the fixed limits of various
arrays in the version of TSP you're using.

Improved list processing, with expressions expressions like A0-A2 (starting
with zeroes), X(-1)-X(-1) (beginning and ending the same), L1A-L10A, and
M1A1-M10A1 (internal index), being allowed.

Improved error-handling and reporting of numerical errors in nonlinear
procedures.  In SOLVE, the equation number is reported when there is a
numerical error.

Equations non-differentiable at a finite number of points (such as those
involving logical expressions) are now allowed for estimation or simulation.
The derivative is defined to be zero at those points.

Improved MISSING VALUE report names the series with the missing values and how
many are in each series.  Regressions with missing values will now store
@RES, @FIT, and @DW (they are aware of the implied SELECT).

More accurate digamma and trigamma functions when the argument is larger than 1
have been installed.  Improved gamma function using ACM algorithm #291.
