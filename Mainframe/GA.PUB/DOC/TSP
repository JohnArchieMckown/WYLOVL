DOC#TSP PUBLIC                               Latest update:  12/19/86
Information Technology Services              Creation date:  04/30/84
Stanford University                          Length:        332 lines

                    Version 4.1 Enhancements

                          NEW COMMANDS

 Qualitative Variable and General Maximum Likelihood Estimation

LIML  -- Limited Information Maximum Likelihood estimation for  a
single  linear equation (FIML handles the nonlinear  case).   The
computation  is  done with the standard  eigenvalue  and  K-class
method,  and the K-class constant can be modified with the FULLER
option for improved small-sample properties.

LOGIT  -- estimates  the  following  Logit  models:   Multinomial
(observation- or    chooser-specific   explanatory    variables),
Conditional (choice-specific variables), and Mixed (both types of
variables).  Handles multiple/variable observations per case.  In
Multinomial,  the coefficients of the first choice are normalized
to  zero (like PROBIT).   There are no restrictions on the number
of choices or the number of variables.

ML -- general Maximum Likelihood estimation.   The user  supplies
the  log likelihood function in a FRML.   Automatically  computes
analytic  first (and optionally) second derivatives.   Useful for
special models like truncation and ordered Probit.

PROBIT -- estimates the Probit model (0/1 dependent variable with
normal errors).

SAMPSEL  -- estimates the two-equation sample selection model  by
maximum  likelihood.   Default  starting values from  Probit  and
regression.

TOBIT -- estimates the Tobit model (0/positive dependent variable
with normal errors).


                       Other new commands

DUMMY -- creates seasonal and general dummy variables.

EQSUB -- performs equation substitution.   Useful with  ML,  LSQ,
and FIML.

HIST -- makes Histograms/bar charts.

SELECT -- selects observations for processing.   Like SMPLIF, but
non-nested.


                      GENERAL NEW FEATURES


New interface for nonlinear estimation.   This allows for control
of  the Hessian approximation for iterations and standard errors,
and multiple sets of standard errors printed for one  estimation.
DFP  (numerical  optimization) available for  all  models,  WHITE
(standard  errors robust to misspecification) available for most.
Improved  handling of numerical errors.   Faster  differentiation
and optimized derivative code,  resulting in 60% faster execution
for some nonlinear LSQ models and cleaner formulas in DIFFER.

New  functions for:   square root,  log base  10,  inverse  Mills
ratio,  Gamma  function,  Factorial,  Sign function,  Positive  =
max(0,X), Missing value detection, truncation to nearest integer.

Improved  memory  management,  with a concise summary  of  memory
requirements  at  the end of the run,  and the ability  to  parse
arbitrarily large formulas.

Improved  missing value processing.   Missing data is handled  by
dropping incomplete observations in OLSQ,  INST,  LIML,  MSD, and
GRAPH.   User  control  in  formulas is possible with  @MISS  and
MISS().

Dynamic  processing of equations with lagged dependent  variables
in  GENR,  FORCST,  SIML,  and SOLVE is now  the  default.   When
estimating  these  models,  AR1 now computes consistent  standard
errors,    and   OLSQ   constructs   a   consistent   test    for
autocorrelation.

R-squared  is now always non-negative -- it is now defined as the
squared  correlation between Y and YFIT.   The SILENT  option  is
available in OLSQ, INST, LIML, and AR1.

Extended  list processing -- lists like DOT 1-20;   or  UNMAKE  M
M1-M10;   work  everywhere (not just in the LIST  command).   Lag
lists  also work:   OLS Y C X(-1)-X(-3);   =  OLS Y C X(-1) X(-2)
X(-3); .

Subscripts  for  dated series now  work  correctly,  either  like
X(76:2),  or  with  a variable subscript relative to the  current
SMPL   -- X(I)  =  X(76:2)  for  I=1  under  SMPL   76:2,...;   .
Subscripted  matrices  and vectors are now legal  in  GENR,  like
YFIT  = @COEF(1) + @COEF(2)*X;   .   GENR also works  dynamically
with lagged dependent variables, e.g. U = RHO*U(-1) + E; .

The  size of matrices is no longer limited by the maximum  number
of  observations.   Inversion  and  factorization  of  indefinite
symmetric matrices has been improved.   MMAKE and UNMAKE now work
on both scalars and series.


                  NEW FEATURES IN OLD COMMANDS

FIML  -- the standard errors have been fixed.  The  new  standard
errors are consistent and have good small-sample properties.  The
old  standard  errors  were computed from the  concentrated  BHHH
matrix  (without  covariance parameters),  and  had  fairly  good
small-sample behavior,  but were not technically consistent.  The
new  standard  errors are computed from the  unconcentrated  BHHH
matrix and are generally larger than the old ones.

LOAD/READ -- in a free-format read, . (period/dot) is interpreted
as a missing value.

MFORM -- can initialize any matrix to a constant (like 0 or 1).

MSD  -- now stores the vectors @MEAN,@STDDEV,@MIN,@MAX,@SUM,@VAR,
which are easier to use than the @MSD matrix.

OLSQ -- the HI option stores the series @HI = diag X(X'X)**(-1)X'
(hat matrix) for robust/influence diagnostics.

RANDOM  -- new  options allow generation of  multivariate  normal
random  numbers,   random  draws  from  empirical   distributions
(bootstrapping), and operations on the random seed.

SMPLIF -- expressions are now legal,  like  SMPLIF G<5;   .   See
also the new SELECT command.

TREND -- new options allow for a repeating trend (like quarter in
quarterly data or year in panel data).



          Differences between Versions 4.1, 4.0 and 3.5

Briefly,  Version  3.5  (1981-84) contains the basic features  of
TSP,  but  has  poor (numbered) error messages,  no  handling  of
missing  values,  and  awkward matrix  procedures.   Version  4.0
(1984-86)  corrects  these weaknesses  and  includes  Box-Jenkins
(ARIMA)  procedures,  dated  time series,  control of output  for
printer  or screen,  random number  generation,  heteroskedastic-
consistent  standard  errors,  and numerous  other  improvements.
Interactive  (1985)  allows  immediate  execution  of   commands,
command editing (including ADD/DROP for regressions), and command
input/output from/to external files.  Version 4.1 (1986) contains
several new estimation procedures (LIML,  PROBIT, TOBIT, SAMPSEL,
LOGIT,  ML) along with a wide range of enhancements.


          Non-upward compatible changes / changes in defaults


AR1  for lagged dependent variable(s), @COEF, @SE, @VCOV now include
RHO.  The standard errors are now consistent.  The old output could be
generated (if necessary) by changing the names of the lagged dependent
variables (or the dependent variable).

FIML  the standard errors are now consistent (see above).   There is no
way to reproduce the old standard errors.

FORCST  the default is now DYNAMIC for lagged dependent variable(s).  If
necessary, STATIC can be used to reproduce old results.

GENR  the default is now dynamic for lagged dependent variable(s).  A
static GENR could be done by renaming the dependent variable.  A note is
also printed when GENR is operating dynamically.

INV  for symmetric (and diagonal) matrices, the old program used to
compute a generalized inverse if the matrices were not positive
definite.  This is not correct for non-positive-definite matrices (such
as negative definite matrices).  The new method is to use the Gauss-
Jordan method to invert the matrix (which works for non-positive-
definite matrices).  To reproduce the old results (generalized inverse
when the matrix is not positive definite), use the YINV command.  This
is especially useful for Hausman/Wu specification tests.

LSQ  for ROBUST option, both the robust and regular standard errors are
printed.  Use  HCOV=R  to suppress the regular (Gauss) standard errors.

PLOT  the INTEGR option is now spelled INTEGER.

RANDOM  the UNIFRM option is now spelled UNIFORM.

SIML  the default is now DYNAMIC for lagged dependent variable(s).  If
necessary, STATIC can be used to reproduce old results.

SOLVE  the default is now DYNAMIC for lagged dependent variable(s).  If
necessary, STATIC can be used to reproduce old results.


Miscellaneous

@MEAN is now @YMEAN in regression output.  @MEAN is now used by MSD.

The lagged series POS(-1) is now treated as a function POS(-1).  This
type of change applies to all the newly implemented function names, and
to their four-letter abbreviations (such as DLCN for DLCNORM).  Old
results can be duplicated by renaming the series with conflicting names.


New Functions:  (all are differentiable unless noted)

Math:
  SQRT = square root
  LOG10 = log base 10 (as opposed to base e / natural log)

Normal distribution:
  LCNORM = log of cumulative normal.  Useful for ML command
  DLCNORM = derivative of LCNORM = inverse Mills ratio
  LNORM = log of normal density

Gamma:
  GAMFN = Gamma function (not density)
  LGAMFN = log of Gamma function
  DIGAMMA/DLGAMFN = first derivative of LGAMFN
  TRIGAMMA = second derivative of LGAMFN   (non-differentiable)
  FACT = Factorial.  FACT(X) = X! = GAMFN(X+1)
  LFACT = log of factorial

Miscellaneous:
  SIGN = -1 for X<0, 0 for X=0, 1 for X>0.  Derivative of ABS
  POS/POSITIVE = max(0,X).  Useful for SIML/SOLVE constraints.
    Note:  "min(A,B)" = B - POS(B-A) ,
           "max(A,B)" = A + POS(B-A) .
  MISS = 1 when argument is a missing value, 0 otherwise

Integer:  (all are non-differentiable)
  INT/FLOOR/TRUNC = round down to nearest integer: INT(1.8) = 1,
                      INT(-1.8) = -1  (round towards zero).
  CEIL/CEILING    = round up to nearest integer:  CEIL(1.8) = 2
  ROUND           = round to nearest integer:    ROUND(1.5) = 2

********************************************************************


                 NEW FEATURES AND CHANGES IN TSP 4.0

GENERAL FEATURES:

Input may be either upper or lower case.  You may specify the number
of columns to be read, allowing sequence numbers to be included in
your input.  GENR is no longer required in front of data
transformation statements.

Output appearance has been improved and many internal changes have
been made, in preparation for an interactive version of TSP and to
improve data storage.

Free format data reading may be done anywhere in the program.
Limitations on the number of such datapoints that can be read at one
time have been removed.

When using symbolic differentiation of TSP equations, the resulting
equation may be printed or computed just like any other TSP equation.

With the dating of time series, all series are now stored with
frequency and starting date and may be referred to by date when
choosing observations.  A CONVERT procedure to change the frequency
of a series is provided.

Missing values are automatically generated as a result of illegal
arithmetic operations on time series.  These values propagate to any
new series that are created from series with missing values.  When
series with missing values are used in the current sample, either a
warning is printed (in procedures such as PRINT or GENR) or the
procedure terminates with an error (the estimation procedures).

Matrices are stored with their dimensions and type, so you do not
have to supply them.  Several new matrix procedures have been added
to create, load, and reform matrices.

Options now control the width of TSP input and printer output.

Named lists of variables may be included anywhere in the program.
These lists may be of the form VARA, VARB, etc.  or of the form
VAR1-VAR5.

Error messages are now concise English phrases and the data in error
is printed in a readable format.  Error numbers have been eliminated,
so you no longer need to look them up in the manual.


STATISTICAL AND ECONOMETRIC FEATURES:

Box-Jenkins identification, estimation, and forecasting have been
added for univariate time series models.

The random number generator can be used for normal, uniform, and
Poisson random variates.

New easier-to-use syntax has been inserted for retrieval of
estimation results.  These include the addition of multi-equation
output, the gradient of the objective function, and the convergence
status to the set of retrievable results.

Optional computation of heteroskedastic-consistent standard errors in
the OLSQ, INST, or LSQ procedures is possible by using formulas
popularized by Halbert White.

DOT, the multi-sectoral procedure, has been enhanced to allow
multiple DOT loops, numerical sector suffixes, and dots (.) imbedded
in the variable names.

Several new functions have been made available for variable
transformation and nonlinear equation estimation:  sine, cosine,
tangent, arctangent, normal density, and the cumulative normal.

Estimation of AR1 models is made with PDL variables.  An unlimited
number of PDL variables may be included in any linear estimation
procedure (OLSQ, INST, or AR1) providing improved accuracy of the PDL
variable transformation.

Enhanced hypothesis testing with ANALYZ is automatically performed.
ANALYZ is a Wald test for the hypothesis that all the derived
parameters (or restrictions) are zero.  Parameters and their
estimated variance-covariance may be supplied directly to ANALYZ
rather than being retrieved from the last estimation.

An equation that was estimated by the AR1 procedure can now be easily
saved using the FORM procedure.  This enables you to use such an
equation in model simulation without having to enter it in algebraic
form.

Addition of THSLS and SUR commands for three stage least squares and
seemingly unrelated regression automates the setting of LSQ options
for these methods.
